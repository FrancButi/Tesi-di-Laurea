\chapter{Conclusioni}
In questa tesi, è stata presentata una sperimentazione sull’uso di tecniche ispirate al Chaos Engineering per testare e valutare il comportamento di FogMon, un prototipo di monitoraggio non intrusivo distribuito per reti Fog, in condizioni di turbolenza della rete (es. fallimento di nodi, degradazione della QoS dei collegamenti). Dopo aver riepilogato alcune conoscenze preliminari necessarie (Capitolo 2), è stato descritto il processo di pianificazione e implementazione degli esperimenti (Capitolo 3) e il set di risultati ottenuti (Capitolo 4).
Di seguito saranno descritti questi risultati , per quanto riguarda la progettazione, l'implementazione e l'esito della sperimentazione, oltre a una considerazione sui possibili sviluppi futuri di questo progetto.
    
    \section{Discussione Critica dei Risultati Ottenuti}
    In questa sezione sono descritti gli esiti del lavoro svolto, valutando i vantaggi e gli svantaggi degli esperimenti di \textit{Chaos Engineering} applicati, e l'esito della sperimentazione, per discutere le informazioni ottenute e confrontarle con gli obiettivi iniziali.
        
        \paragraph{Vantaggi della sperimentazione}\mbox{}\\
            
        Gli esperimenti condotti hanno portato alla scoperta di alcune deviazioni nell'esecuzione di FogMon, (come evidenziato nella Sezione 4.1) e, conseguentemente, hanno permesso di correggere tali errori per migliorare la resilienza del prototipo. L'applicazione delle tecniche ispirate al \textit{Chaos Engineering} dunque ha portato al raggiungimento dell'obiettivo iniziale di evidenziare falle in FogMon e di fornire dati utili per metterlo a punto di conseguenza.
        
        Non è possibile escludere a priori che tali errori potessero essere rilevati anche con altre modalità di testing, ma in generale, possiamo intuire come le tecniche di \textit{Chaos Engineering} possano rivelarsi utili nel rinforzare la \textit{fault tolerance} dei sistemi distribuiti. Nel caso peggiore (ossia quando la sperimentazione non dovesse portare alla scoperta di deviazioni), l'investimento necessario a effettuare i test conferma la validità e la resilienza del software e fornisce dati importanti, grazie monitoraggio del suo comportamento; in tutti gli altri scenari, apporta informazioni preziose ad aumentare la resilienza del software testato.
        
        Un altro risultato fondamentale di questo lavoro consiste nel contributo apportato al progetto LiSCIo: la sperimentazione ha permesso di fornire un ampio set di dati di testing. In particolare, nel rapporto conclusivo di LiSCIo \cite{FogMon} si descrive anche la fase di test di FogMon, di cui fanno parte i \textit{Node failure} e i \textit{Link failure} e i cui dati sono in parte derivanti dagli esperimenti condotti per questa tesi. Ad esempio, la fase di testing di FogMon comprende un'area di \textit{soft failure}, ossia di fallimenti più probabili e relativamente poco incisivi sul funzionamento del prototipo, costituita interamente dalle applicazioni dei metodi di \textit{Follower failure} descritte in 3.1.2. e, pertanto, coincidenti con quanto svolto ai fini di questa tesi. 
        
        Altri contributi riguardano il testing di alcune topologie per i metodi \textit{Leader failure} e \textit{Leader-Follower failure}, i cui risultati sono in parte ripresi dalla sperimentazione eseguita con le tecniche ispirate al \textit{Chaos testing}. 
        
        Infine, le fasi preliminari della sperimentazione sui \textit{Link failure} e \textit{Node failure}, descritte nel Capitolo 4, hanno evidenziato alcuni problemi nel calcolo dell'errore della QoS di rete in FogMonEye, tempestivamente corretti e integrati nelle rilevazioni riportate in 4.2.2.
        
        
        \paragraph{Svantaggi della sperimentazione}\mbox{}\\
        
        Il lavoro svolto, tuttavia, incontra alcuni limiti. Ad esempio, le ipotesi descritte nella Sezione 3.1 descrivono buona parte del comportamento di FogMon in condizioni di buon funzionamento, ma la verifica delle operazioni di \textit{gossiping} dei leader richiede maggiore attenzione. 
        In particolare, sarebbe opportuno intensificare il controllo dei dati scambiati tra i Leader per verificare che i loro database presentino le informazioni corrette al termine delle comunicazioni tra gruppi. Questa sperimentazione può essere effettuata andando a definire una quarta ipotesi, che assuma il funzionamento delle appena citate operazioni di \textit{gossiping}. Seguendo poi l'iter descritto al Capitolo 3, dovrebbero essere definite delle metriche per la misurazione della correttezza dei parametri per valutare tale ipotesi. I metodi utilizzati e descritti nella Sezione 3.1.2, intuitivamente, dovrebbero essere in grado di coprire anche gli esperimenti per questa nuova ipotesi.
            
        Inoltre, eseguire più esperimenti contemporaneamente richiede di avviare istanze diverse di FogMonK, che non fornisce nativamente la possibilità di eseguire più test allo stesso momento. I metodi applicati (e i cui risultati sono descritti nella Sezione 4.2) non sono stati parallelizzati, ma il Chaos Engineering incoraggia la sperimentazione di più ``turbolenze" simultanee. Sarebbe interessante, ad esempio, combinare un \textit{Follower failure} con il \textit{Link failure} del Leader di riferimento per testare la velocità di reazione del Leader stesso, oppure integrare lo \textit{Stress Test} con il \textit{Link failure} per verificare la velocità di FogMon nel propagare i peggioramenti delle condizioni dei nodi in condizioni di rete ostili.

    \section{Possibili Sviluppi Futuri}
    Il prosieguo di questa sperimentazione può includere alcune migliorie a FogMonK e al piano di test. In particolare:
    \begin{itemize}
        \item Effettuare un periodo ulteriore di osservazione per includere nel piano degli esperimenti la verifica del \textit{Gossiping}, con la formulazione di un'ipotesi e l'assegnazione delle relative metriche di valutazione e dei metodi.
        \item Integrare il supporto a più esperimenti di Chaos contemporanei in modo da creare condizioni di \textit{Chaos} più complete e simulare fallimenti simultanei, perfezionando il sistema di verifica delle ipotesi per gestire più riconfigurazioni e monitorare l'applicazione di più Metodi
        \item Per la verifica dell'ipotesi \textbf{Tempo massimo di configurazione} (H1), descritta nella Sezione 3.1, sarebbe utile estendere le funzionalità di FogMonK, aumentando il periodo di monitoraggio, fino a includere la fase di riconfigurazione di FogMon che, al momento, è ignorata. Questa intensificazione dei controlli consentirebbe di fornire più dati utili nel caso in cui si dovessero scoprire ulteriori deviazioni (ad esempio, nella verifica di una nuova \textit{Steady state hypotesis} basata sulle operazioni di \textit{gossiping}).
        \item La natura di FogMonK, improntata all'ispezione e al monitoraggio dell'attività di FogMon, rende difficile salire di livello e renderlo uno strumento di Chaos Engineering per tutte le applicazioni distribuite. Per fare ciò, è necessario invece creare un nuovo prototipo incentrato sul \textit{fault management}, ma con delle API che permettano di implementare la verifica delle ipotesi tramite delle metriche personalizzabili. In tal modo, sarebbe possibile fornire uno strumento più completo di quelli attuali (come i software descritti nella Sezione 3.2) che sono unicamente volti al \textit{fault injection} e non si occupano di implementare le fasi successive di un \textit{Chaos Experiment}.
    \end{itemize}
    